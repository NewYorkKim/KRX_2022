{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf23d1af",
   "metadata": {},
   "source": [
    "# 제1회 KRX 금융 빅데이터 활용 아이디어 경진대회"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e87072",
   "metadata": {},
   "source": [
    "## 주제 : 개인투자자의 ktop30 감정지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1331fca",
   "metadata": {},
   "source": [
    "- __chapter 1. 크롤링__\n",
    "    - 유튜브댓글 api\n",
    "    - 네이버금융 종목토론방 댓글 크롤링\n",
    "- __chapter 2. 데이터 전처리__\n",
    "    - 댓글 전처리\n",
    "    - 댓글 토크나이징\n",
    "    - 댓글 레이블링\n",
    "    - 학습데이터 생성 (댓글 도미넌스 기반 랜덤추출)\n",
    "- __chapter 3. Bert 모델링__\n",
    "- __chapter 4. 시각화 및 서비스__\n",
    "\n",
    "\n",
    "- Reference\n",
    "    - [한국거래소](http://www.krx.co.kr/main/main.jsp)\n",
    "    - [네이버 금융](https://finance.naver.com/)\n",
    "    - [CNN Fear & Greed Index](https://edition.cnn.com/markets/fear-and-greed) -> 정형지표만 이용한듯 해요\n",
    "    - [Crypto Fear & Greed Index](https://alternative.me/crypto/fear-and-greed-index/)\n",
    "    - 단어집 위치\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e841c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3d17f",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "    금융시장은 투자자의 시장인식에 따라 영향이 있을것이라 생각했습니다. 국내에서는 심리를 대변하는 지수로 정형지표의 계산으로 산출된 VIX지수를 지표로 이용합니다. 그러나 Crypto Fear & Greed Index 에서 비정형 데이터로 트위터 데이터를 산출식에 포함시키는 시도가 있었습니다. (가이드글)\n",
    "\n",
    "    # 개인투자자의 시장인식이 댓글형태로 나타나는 네이버 종목토론실 댓글을 이용합니다. # 개인투자자의 시장인식을 수치화시켜 하나의 지표로 만들었습니다. # KODEX30 으로 프로토타입을 작성했습니다.\n",
    "\n",
    "    인덱스가 FEAR(0)에 가까울수록 투자자가 느끼는 시장인식은 가격이 하락하고 있음을 대변합니다. 인덱스 활용방법으로는 매수시점을 정하는데 도움을 받을 수 있습니다. 반대의 경우 가격이 상승하는것을 대변하고, 매도시점을 정하는데 도움을 받을 수 있습니다.\n",
    "\n",
    "\n",
    "- 사용데이터소개 (비정형/정형)\n",
    "- 인덱스의 기대효과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c706e6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8b34f4",
   "metadata": {},
   "source": [
    "# chapter 1. 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778b669a",
   "metadata": {},
   "source": [
    "### 1.1 유튜브댓글 api\n",
    "- 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d72e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3fee961",
   "metadata": {},
   "source": [
    "### 1.2 종목토론실 댓글 크롤링\n",
    "- 종목토론실 댓글에서 '날짜', '댓글제목', '조회수', '좋아요', 싫어요' 를 크롤링 했습니다.\n",
    "- 기업대상은 KODEX30의 기업입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045505b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38706b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(symbol):\n",
    "    krx = pd.read_csv('./krx_code.csv',encoding='utf-8')\n",
    "    krx = krx.set_index('한글 종목약명')\n",
    "    try:\n",
    "        code = krx.at[symbol,'단축코드']\n",
    "        return code\n",
    "    except:\n",
    "        print('종목명을 다시 확인해주세요.')\n",
    "        return 0\n",
    "\n",
    "def get_comment_csv(symbol,page,year,month,day):   \n",
    "    code = get_code(symbol)\n",
    "    date_list = [] # 날짜\n",
    "    comment_list = [] # 댓글\n",
    "    view_list = [] # 조회수\n",
    "    good_list = [] # 좋아요\n",
    "    bad_list = [] # 싫어요\n",
    "    flag = 0\n",
    "    for i in range(1,page+1):\n",
    "        url = f'https://finance.naver.com/item/board.naver?code={code}&page={i}'\n",
    "        headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 Edg/100.0.1185.50'}\n",
    "        res = requests.get(url, headers = headers)\n",
    "        bs = BeautifulSoup(res.text, 'html.parser')\n",
    "        for j in range(20):\n",
    "            try:\n",
    "                root = bs.find('div',{'class':'section inner_sub'}).find_all('tr',{'onmouseover':'mouseOver(this)'})[j].text.split('\\n')\n",
    "                \n",
    "                date_list.append(root[1].replace('.','-'))\n",
    "                \n",
    "                if len(root) == 14: # 답글\n",
    "                    comment_list.append('답글:'+root[4])\n",
    "                    view_list.append(root[10])\n",
    "                    good_list.append(root[11])\n",
    "                    bad_list.append(root[12])          \n",
    "                elif len(root) == 13: # 기본\n",
    "                    comment_list.append(root[3])\n",
    "                    view_list.append(root[9])\n",
    "                    good_list.append(root[10])\n",
    "                    bad_list.append(root[11])\n",
    "                else: # 에러\n",
    "                    comment_list.append('error')\n",
    "                    view_list.append(0)\n",
    "                    good_list.append(0)\n",
    "                    bad_list.append(0)   \n",
    "            except:\n",
    "                break\n",
    "#                 date_list.append('error')\n",
    "#                 comment_list.append('error')\n",
    "#                 view_list.append(0)\n",
    "#                 good_list.append(0)\n",
    "#                 bad_list.append(0)  \n",
    "            tp = [int(j) for j in root[1].split()[0].split('.')]\n",
    "            if dt.datetime(tp[0],tp[1],tp[2]) < dt.datetime(year,month,day):\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 1:\n",
    "            break\n",
    "        print(f'\\r{i}페이지 크롤링 완료.',end='')\n",
    "        \n",
    "#         for i in date_list:\n",
    "#             tp = [int(j) for j in i.split()[0].split('-')]\n",
    "#             if dt.datetime(tp[0],tp[1],tp[2]) < dt.datetime(year,month,day):\n",
    "#                 flag = 1\n",
    "#                 break\n",
    "#         if flag == 1:\n",
    "#             break\n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    df['날짜'] = date_list\n",
    "    df['댓글'] = comment_list\n",
    "    df['조회수'] = view_list\n",
    "    df['좋아요'] = good_list\n",
    "    df['싫어요'] = bad_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b68a02",
   "metadata": {},
   "source": [
    "- ktop30 리스트 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b9340",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel('./KODEX_KTOP_30_20220629.xlsx',header=2).drop(0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "ktop30_company = pd.read_excel('./KODEX_KTOP_30_20220629.xlsx',header=2).drop(0,axis=0)['종목명']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c5777",
   "metadata": {},
   "source": [
    "- 샘플 실행결과 입니다. \n",
    "- 인풋 파라미터는 기업이름,최대 페이지수,년,월,일 입니다. 설정한 년/월/일 이후의 댓글이 나오면 크롤링을 멈추게 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db94e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_comment_csv('미래에셋증권',500,2022,6,1) # sample\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2efed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 건너뛰기\n",
    "for i in range(3):\n",
    "    df = get_comment_csv(list(ktop30_company)[i],100000,2020,6,1)\n",
    "    #df = df[df['날짜']=='2022-07-01']\n",
    "    df.to_csv(f'./src/2year_time/{list(ktop30_company)[i]}_2year.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9112c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링된 데이터 확인\n",
    "pd.read_csv('./src/year_time/삼성전자_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dde1dd",
   "metadata": {},
   "source": [
    "# chapter 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b842532a",
   "metadata": {},
   "source": [
    "### 2.1 댓글 전처리\n",
    "- 온전한 한글문자 이외에 모든 부분을 제거했습니다.\n",
    "- 초성,알파벳,특수문자,이모티콘 등이 제거 되었습니다.\n",
    "\n",
    "\n",
    "- 예시 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d38b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804091bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('./src/2year_time/삼성화재_2year.csv')\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e6a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sents_df(company):\n",
    "    try:\n",
    "        target = pd.read_csv(f'./src/{company}_2year.csv',encoding='utf8').drop('Unnamed: 0',axis=1)\n",
    "    except:\n",
    "        target = pd.read_csv(f'./src/{company}_2year.csv',encoding='utf8')\n",
    "\n",
    "    if company == 'sampro':\n",
    "        target.rename(columns={'comment':'댓글'},inplace=True)\n",
    "    df = target\n",
    "    df['정제된 댓글'] = df['댓글'].str.replace('\\\\[삭제된 게시물의 답글\\\\]',' ')\n",
    "    df['정제된 댓글'] = df['정제된 댓글'].str.replace('답글:',' ')\n",
    "    df['정제된 댓글'] = df['정제된 댓글'].str.replace('[^가-힣]',' ').str.replace(' +',' ').str.strip()\n",
    "    df = df[df['정제된 댓글'] != '']\n",
    "    df = df.reset_index(drop=True)\n",
    "    return  df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5632e0c8",
   "metadata": {},
   "source": [
    "### 2.2 댓글 토크나이징\n",
    "\n",
    "- Bert 모델링을 위한 labeling 사전작업 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c36608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_save(company):\n",
    "    df = clean_sents_df(company)\n",
    "    df['정제된 댓글 길이'] = [len(str(i)) for i in df['정제된 댓글']]\n",
    "    df = df[df['정제된 댓글 길이'] > 5]\n",
    "\n",
    "    tp = [str(i) for i in list(df['정제된 댓글'])]\n",
    "    save = '\\n'.join(tp)\n",
    "    f = open(\"./corpus_target.txt\", 'a',encoding='utf8')\n",
    "    f.write(save)\n",
    "    f.close()\n",
    "    \n",
    "def corpus_init():\n",
    "    ktop30_company = pd.read_excel('./src/KODEX_KTOP_30_20220629.xlsx',header=2).drop(0,axis=0)['종목명']\n",
    "    company_set = list(ktop30_company)\n",
    "    company_set.append('sampro')\n",
    "    f = open(\"./corpus_target.txt\", 'w',encoding='utf8')\n",
    "    f.write('')\n",
    "    f.close()\n",
    "    for company in company_set:\n",
    "        corpus_save(company)\n",
    "\n",
    "def return_tokenizer():\n",
    "    corpus = DoublespaceLineCorpus(\"./src/corpus_target.txt\",iter_sent=True)\n",
    "    noun_extractor = LRNounExtractor_v2(verbose=True)\n",
    "    nouns = noun_extractor.train_extract(corpus)\n",
    "    scores = {word:score.score for word, score in nouns.items()}\n",
    "    tokenizer = LTokenizer(scores=scores)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c2234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_init()\n",
    "tokenizer = return_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0289c97",
   "metadata": {},
   "source": [
    "- 3181878 개의 네이버 종목토론방, 유튜브 댓글을 학습시키고, 학습된 tokenizer를 이용하여 전처리 댓글을 토큰화 시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c9b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = clean_sents_df('삼성전자')\n",
    "target_df['토큰화 댓글'] = [tokenizer(str(i)) for i in target_df['정제된 댓글']]\n",
    "target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765422c1",
   "metadata": {},
   "source": [
    "### 2.3 댓글 레이블링\n",
    "- fear_words_set 과 greed_words_set을 설정하고 토크나이징댓글의 요소가 fear 단어집에 있으면 -1씩 greed 단어집에 있으면 +1씩 부여했습니다.\n",
    "- 양수인경우 greed, 음수인경우 fear로 labeling 했습니다. 0 인경우 일단 데이터프레임에 기록되고, 최종적으로 train_data 선정시에는 제외됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c81e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(target_df):\n",
    "    \n",
    "    f = open(\"./neg_pol_word.txt\", 'r',encoding='utf8')\n",
    "    words = f.readlines()\n",
    "    f.close()\n",
    "    fear_words_set = {word.strip('\\n') for word in words}\n",
    "\n",
    "    f = open(\"./pos_pol_word.txt\", 'r',encoding='utf8')\n",
    "    words = f.readlines()\n",
    "    f.close()\n",
    "    greed_words_set = {word.strip('\\n') for word in words}\n",
    "    \n",
    "    label_score = []\n",
    "    for token_list in target_df['토큰화 댓글']:\n",
    "        sent_score = 0\n",
    "        for token in token_list:\n",
    "            if token in fear_words_set:\n",
    "                sent_score -= 1\n",
    "            elif token in greed_words_set:\n",
    "                sent_score += 1\n",
    "\n",
    "        if sent_score < 0:\n",
    "            label_score.append(-1)\n",
    "        elif sent_score > 0:\n",
    "            label_score.append(1)\n",
    "        else:\n",
    "            label_score.append(0)\n",
    "            \n",
    "    target_df['label'] = label_score\n",
    "    \n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c142d956",
   "metadata": {},
   "source": [
    "### 2.4 학습데이터 생성\n",
    "\n",
    "- 학습데이터는 종목토론실 댓글에서 3만개, 유튜브 댓글에서 1만개 랜덤추출 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831a4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting_train_data():\n",
    "    company = list(pd.read_excel('./KODEX_KTOP_30_20220715.xls',header=2)['종목명'][1:])\n",
    "    dominance = list(pd.read_excel('./KODEX_KTOP_30_20220715.xls',header=2)['비중(%)'][1:])\n",
    "\n",
    "    train_data = pd.DataFrame(columns=['날짜','댓글','조회수','좋아요','싫어요','정제된 댓글','토큰화 댓글','label'])\n",
    "    for idx in range(30):\n",
    "        target_df = clean_sents_df(company[idx])\n",
    "        target_df['토큰화 댓글'] = [tokenizer(str(i)) for i in target_df['정제된 댓글']]\n",
    "        \n",
    "        label_df = labeling(target_df)\n",
    "        \n",
    "        label_df = label_df[label_df['label'] != 0] # except label:0 \n",
    "        label_df = label_df.sample(int(30000*dominance[idx])+1,replace=True) # replace option : 샘플수가 부족할경우 중복이 생김 ** 추후 수정\n",
    "        train_data = train_data.append(label_df)\n",
    "    \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c884cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = setting_train_data()\n",
    "train_data.reset_index(inplace=True)\n",
    "train_data.drop('index',axis=1,inplace=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e6bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삼프로\n",
    "target_df = clean_sents_df('sampro')\n",
    "target_df['토큰화 댓글'] = [tokenizer(str(i)) for i in target_df['정제된 댓글']]\n",
    "label_df = labeling(target_df)\n",
    "\n",
    "label_df = label_df[label_df['label'] != 0] # except label:0 \n",
    "label_df = label_df.sample(10000,replace=True) # replace option : 샘플수가 부족할경우 중복이 생김 ** 추후 수정\n",
    "train_data = train_data.append(label_df)\n",
    "\n",
    "train_data = train_data.loc[:,['정제된 댓글','label']].reset_index().drop('index',axis=1)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d72d56",
   "metadata": {},
   "source": [
    "# chapter 3. Bert 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622b870",
   "metadata": {},
   "source": [
    "# chapter 4. 시각화 및 서비스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d7a93d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4498ab0c90896f65e68d27b1867a45d07756addaa4b72492727e86f1984461f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
