{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf23d1af",
   "metadata": {},
   "source": [
    "# 제1회 KRX 금융 빅데이터 활용 아이디어 경진대회"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e87072",
   "metadata": {},
   "source": [
    "## 주제 : 개인투자자의 ktop30 감정지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1331fca",
   "metadata": {},
   "source": [
    "- __chapter 1. 크롤링__\n",
    "    - 유튜브댓글 api\n",
    "    - 네이버금융 종목토론방 댓글 크롤링\n",
    "- __chapter 2. 데이터 전처리__\n",
    "    - 댓글 전처리\n",
    "    - 댓글 토크나이징\n",
    "    - 댓글 레이블링\n",
    "    - 학습데이터 생성 (댓글 도미넌스 기반 랜덤추출)\n",
    "- __chapter 3. Bert 모델링__\n",
    "- __chapter 4. 시각화 및 서비스__\n",
    "\n",
    "\n",
    "- Reference\n",
    "    - [한국거래소](http://www.krx.co.kr/main/main.jsp)\n",
    "    - [네이버 금융](https://finance.naver.com/)\n",
    "    - [CNN Fear & Greed Index](https://edition.cnn.com/markets/fear-and-greed) -> 정형지표만 이용한듯 해요\n",
    "    - [Crypto Fear & Greed Index](https://alternative.me/crypto/fear-and-greed-index/)\n",
    "    - 단어집 위치\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e841c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3d17f",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "    금융시장은 투자자의 시장인식에 따라 영향이 있을것이라 생각했습니다. 국내에서는 심리를 대변하는 지수로 정형지표의 계산으로 산출된 VIX지수를 지표로 이용합니다. 그러나 Crypto Fear & Greed Index 에서 비정형 데이터로 트위터 데이터를 산출식에 포함시키는 시도가 있었습니다. (가이드글)\n",
    "\n",
    "    # 개인투자자의 시장인식이 댓글형태로 나타나는 네이버 종목토론실 댓글을 이용합니다. # 개인투자자의 시장인식을 수치화시켜 하나의 지표로 만들었습니다. # KODEX30 으로 프로토타입을 작성했습니다.\n",
    "\n",
    "    인덱스가 FEAR(0)에 가까울수록 투자자가 느끼는 시장인식은 가격이 하락하고 있음을 대변합니다. 인덱스 활용방법으로는 매수시점을 정하는데 도움을 받을 수 있습니다. 반대의 경우 가격이 상승하는것을 대변하고, 매도시점을 정하는데 도움을 받을 수 있습니다.\n",
    "\n",
    "\n",
    "- 사용데이터소개 (비정형/정형)\n",
    "- 인덱스의 기대효과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c706e6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8b34f4",
   "metadata": {},
   "source": [
    "## chapter 1. 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778b669a",
   "metadata": {},
   "source": [
    "### 1.1 유튜브댓글 api\n",
    "- 유튜브 채널 '삼프로tv'에서 2020년 06월부터 2022년 06월 사이에 업로드된 영상의 댓글을 크롤링하였습니다.\n",
    "- '영상 제목', '영상 업로드 날짜', '영상 아이디', '댓글 내용', '댓글 작성자', '댓글 작성 날짜', '좋아요 수'에 대한 정보를 가져왔습니다.\n",
    "- 국내 시장에 대한 반응을 확인하기 위해 해외 시장에 관련된 영상이나 경제와 관련없는 영상에 달린 댓글들은 제외하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d72e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import scrapetube\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3823ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'api_key'\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "search_response = youtube.search().list(\n",
    "    q = '삼프로tv',\n",
    "    order = 'relevance',\n",
    "    part = 'snippet',\n",
    "    maxResults = 10\n",
    "    ).execute()\n",
    "\n",
    "channel_id = search_response['items'][0]['snippet']['channelId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a78f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = scrapetube.get_channel(channel_id)\n",
    "\n",
    "video_ids = []\n",
    "\n",
    "for video in videos:\n",
    "    video_ids.append(video['videoId'])\n",
    "    \n",
    "len(video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbe701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_infos = []\n",
    "\n",
    "for i in range(800):\n",
    "    start = i * 50\n",
    "    end = (i + 1) * 50\n",
    "    video_request = youtube.videos().list(\n",
    "        part=\"snippet\",\n",
    "        id=','.join(video_ids[start:end]))\n",
    "\n",
    "    video_response = video_request.execute()\n",
    "\n",
    "    for item in video_response['items']:\n",
    "        title = item['snippet']['title']\n",
    "        if ('글로벌 이슈체크' in title) or ('글로벌 마켓브리핑' in title) or ('직장인 vlog' in title):\n",
    "            continue\n",
    "        video_infos.append([item['snippet']['title'], item['snippet']['publishedAt'], item['id']])\n",
    "        \n",
    "df = pd.DataFrame(video_infos, columns=['title', 'video_date', 'id'])\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe46834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "df = df.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9347d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_22 = df[(pd.DatetimeIndex(df.index).year == 2022) & (pd.DatetimeIndex(df.index).month <= 6)]\n",
    "df_21 = df[(pd.DatetimeIndex(df.index).year == 2021)]\n",
    "df_20 = df[(pd.DatetimeIndex(df.index).year == 2020) & (pd.DatetimeIndex(df.index).month >= 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24fc00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_22 = []\n",
    "\n",
    "for video_id in df_22['id']:\n",
    "    api_obj = build('youtube', 'v3', developerKey=api_key)\n",
    "    response = api_obj.commentThreads().list(part='snippet', videoId=video_id, maxResults=100).execute()\n",
    " \n",
    "    while response:\n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']\n",
    "            comments_22.append([video_id, comment['textDisplay'], comment['authorDisplayName'], comment['publishedAt'], comment['likeCount']])\n",
    " \n",
    "        if 'nextPageToken' in response:\n",
    "            response = api_obj.commentThreads().list(part='snippet', videoId=video_id, pageToken=response['nextPageToken'], maxResults=100).execute()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "df1 = pd.DataFrame(comments_22, columns=['id', 'comment', 'author', 'comment_date', 'num_likes'])\n",
    "print(len(df1))\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2678dc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_21 = []\n",
    "\n",
    "for video_id in df_21['id']:\n",
    "    api_obj = build('youtube', 'v3', developerKey=api_key)\n",
    "    response = api_obj.commentThreads().list(part='snippet', videoId=video_id, maxResults=100).execute()\n",
    " \n",
    "    while response:\n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']\n",
    "            comments_21.append([video_id, comment['textDisplay'], comment['authorDisplayName'], comment['publishedAt'], comment['likeCount']])\n",
    "\n",
    "        if 'nextPageToken' in response:\n",
    "            response = api_obj.commentThreads().list(part='snippet', videoId=video_id, pageToken=response['nextPageToken'], maxResults=100).execute()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "df2 = pd.DataFrame(comments_21, columns=['id', 'comment', 'author', 'comment_date', 'num_likes'])\n",
    "print(len(df2))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03981cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_20 = []\n",
    "\n",
    "for video_id in df_20['id']:\n",
    "    api_obj = build('youtube', 'v3', developerKey=api_key)\n",
    "    response = api_obj.commentThreads().list(part='snippet', videoId=video_id, maxResults=100).execute()\n",
    " \n",
    "    while response:\n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']\n",
    "            comments_20.append([video_id, comment['textDisplay'], comment['authorDisplayName'], comment['publishedAt'], comment['likeCount']])\n",
    " \n",
    "        if 'nextPageToken' in response:\n",
    "            response = api_obj.commentThreads().list(part='snippet', videoId=video_id, pageToken=response['nextPageToken'], maxResults=100).execute()\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "df3 = pd.DataFrame(comments_21, columns=['id', 'comment', 'author', 'comment_date', 'num_likes'])\n",
    "print(len(df3))\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e7de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_22 = df_22.reset_index()\n",
    "df_21 = df_21.reset_index()\n",
    "df_20 = df_20.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6260bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampro_22 = pd.merge(df_22, df1, on='id', how='outer')\n",
    "sampro_21 = pd.merge(df_21, df2, on='id', how='outer')\n",
    "sampro_20 = pd.merge(df_20, df3, on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b19ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampro_22.to_csv('./sampro/sampro_22.csv', index=False)\n",
    "sampro_21.to_csv('./sampro/sampro_21.csv', index=False)\n",
    "sampro_20.to_csv('./sampro/sampro_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampro_2year = pd.concat([sampro_22, sampro_21, sampro_20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fee961",
   "metadata": {},
   "source": [
    "### 1.2 종목토론실 댓글 크롤링\n",
    "- 종목토론실 댓글에서 '날짜', '댓글제목', '조회수', '좋아요', 싫어요' 를 크롤링 했습니다.\n",
    "- 기업대상은 KODEX30의 기업입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045505b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38706b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(symbol):\n",
    "    krx = pd.read_csv('./krx_code.csv',encoding='utf-8')\n",
    "    krx = krx.set_index('한글 종목약명')\n",
    "    try:\n",
    "        code = krx.at[symbol,'단축코드']\n",
    "        return code\n",
    "    except:\n",
    "        print('종목명을 다시 확인해주세요.')\n",
    "        return 0\n",
    "\n",
    "def get_comment_csv(symbol,page,year,month,day):   \n",
    "    code = get_code(symbol)\n",
    "    date_list = [] # 날짜\n",
    "    comment_list = [] # 댓글\n",
    "    view_list = [] # 조회수\n",
    "    good_list = [] # 좋아요\n",
    "    bad_list = [] # 싫어요\n",
    "    flag = 0\n",
    "    for i in range(1,page+1):\n",
    "        url = f'https://finance.naver.com/item/board.naver?code={code}&page={i}'\n",
    "        headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 Edg/100.0.1185.50'}\n",
    "        res = requests.get(url, headers = headers)\n",
    "        bs = BeautifulSoup(res.text, 'html.parser')\n",
    "        for j in range(20):\n",
    "            try:\n",
    "                root = bs.find('div',{'class':'section inner_sub'}).find_all('tr',{'onmouseover':'mouseOver(this)'})[j].text.split('\\n')\n",
    "                \n",
    "                date_list.append(root[1].replace('.','-'))\n",
    "                \n",
    "                if len(root) == 14: # 답글\n",
    "                    comment_list.append('답글:'+root[4])\n",
    "                    view_list.append(root[10])\n",
    "                    good_list.append(root[11])\n",
    "                    bad_list.append(root[12])          \n",
    "                elif len(root) == 13: # 기본\n",
    "                    comment_list.append(root[3])\n",
    "                    view_list.append(root[9])\n",
    "                    good_list.append(root[10])\n",
    "                    bad_list.append(root[11])\n",
    "                else: # 에러\n",
    "                    comment_list.append('error')\n",
    "                    view_list.append(0)\n",
    "                    good_list.append(0)\n",
    "                    bad_list.append(0)   \n",
    "            except:\n",
    "                break\n",
    "#                 date_list.append('error')\n",
    "#                 comment_list.append('error')\n",
    "#                 view_list.append(0)\n",
    "#                 good_list.append(0)\n",
    "#                 bad_list.append(0)  \n",
    "            tp = [int(j) for j in root[1].split()[0].split('.')]\n",
    "            if dt.datetime(tp[0],tp[1],tp[2]) < dt.datetime(year,month,day):\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 1:\n",
    "            break\n",
    "        print(f'\\r{i}페이지 크롤링 완료.',end='')\n",
    "        \n",
    "#         for i in date_list:\n",
    "#             tp = [int(j) for j in i.split()[0].split('-')]\n",
    "#             if dt.datetime(tp[0],tp[1],tp[2]) < dt.datetime(year,month,day):\n",
    "#                 flag = 1\n",
    "#                 break\n",
    "#         if flag == 1:\n",
    "#             break\n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    df['날짜'] = date_list\n",
    "    df['댓글'] = comment_list\n",
    "    df['조회수'] = view_list\n",
    "    df['좋아요'] = good_list\n",
    "    df['싫어요'] = bad_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b68a02",
   "metadata": {},
   "source": [
    "- ktop30 리스트 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b9340",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel('./KODEX_KTOP_30_20220629.xlsx',header=2).drop(0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "ktop30_company = pd.read_excel('./KODEX_KTOP_30_20220629.xlsx',header=2).drop(0,axis=0)['종목명']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c5777",
   "metadata": {},
   "source": [
    "- 샘플 실행결과 입니다. \n",
    "- 인풋 파라미터는 기업이름,최대 페이지수,년,월,일 입니다. 설정한 년/월/일 이후의 댓글이 나오면 크롤링을 멈추게 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db94e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_comment_csv('미래에셋증권',500,2022,6,1) # sample\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2efed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 건너뛰기\n",
    "for i in range(3):\n",
    "    df = get_comment_csv(list(ktop30_company)[i],100000,2020,6,1)\n",
    "    #df = df[df['날짜']=='2022-07-01']\n",
    "    df.to_csv(f'./src/2year_time/{list(ktop30_company)[i]}_2year.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9112c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링된 데이터 확인\n",
    "pd.read_csv('./src/year_time/삼성전자_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dde1dd",
   "metadata": {},
   "source": [
    "## chapter 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b842532a",
   "metadata": {},
   "source": [
    "### 2.1 댓글 전처리\n",
    "- 온전한 한글문자 이외에 모든 부분을 제거했습니다.\n",
    "- 초성,알파벳,특수문자,이모티콘 등이 제거 되었습니다.\n",
    "\n",
    "\n",
    "- 예시 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d38b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804091bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('./src/2year_time/삼성화재_2year.csv')\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e6a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sents_df(company):\n",
    "    try:\n",
    "        target = pd.read_csv(f'./src/{company}_2year.csv',encoding='utf8').drop('Unnamed: 0',axis=1)\n",
    "    except:\n",
    "        target = pd.read_csv(f'./src/{company}_2year.csv',encoding='utf8')\n",
    "\n",
    "    if company == 'sampro':\n",
    "        target.rename(columns={'comment':'댓글'},inplace=True)\n",
    "    df = target\n",
    "    df['정제된 댓글'] = df['댓글'].str.replace('\\\\[삭제된 게시물의 답글\\\\]',' ')\n",
    "    df['정제된 댓글'] = df['정제된 댓글'].str.replace('답글:',' ')\n",
    "    df['정제된 댓글'] = df['정제된 댓글'].str.replace('[^가-힣]',' ').str.replace(' +',' ').str.strip()\n",
    "    df = df[df['정제된 댓글'] != '']\n",
    "    df = df.reset_index(drop=True)\n",
    "    return  df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5632e0c8",
   "metadata": {},
   "source": [
    "### 2.2 댓글 토크나이징\n",
    "\n",
    "- Bert 모델링을 위한 labeling 사전작업 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c36608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_save(company):\n",
    "    df = clean_sents_df(company)\n",
    "    df['정제된 댓글 길이'] = [len(str(i)) for i in df['정제된 댓글']]\n",
    "    df = df[df['정제된 댓글 길이'] > 5]\n",
    "\n",
    "    tp = [str(i) for i in list(df['정제된 댓글'])]\n",
    "    save = '\\n'.join(tp)\n",
    "    f = open(\"./corpus_target.txt\", 'a',encoding='utf8')\n",
    "    f.write(save)\n",
    "    f.close()\n",
    "    \n",
    "def corpus_init():\n",
    "    ktop30_company = pd.read_excel('./src/KODEX_KTOP_30_20220629.xlsx',header=2).drop(0,axis=0)['종목명']\n",
    "    company_set = list(ktop30_company)\n",
    "    company_set.append('sampro')\n",
    "    f = open(\"./corpus_target.txt\", 'w',encoding='utf8')\n",
    "    f.write('')\n",
    "    f.close()\n",
    "    for company in company_set:\n",
    "        corpus_save(company)\n",
    "\n",
    "def return_tokenizer():\n",
    "    corpus = DoublespaceLineCorpus(\"./src/corpus_target.txt\",iter_sent=True)\n",
    "    noun_extractor = LRNounExtractor_v2(verbose=True)\n",
    "    nouns = noun_extractor.train_extract(corpus)\n",
    "    scores = {word:score.score for word, score in nouns.items()}\n",
    "    tokenizer = LTokenizer(scores=scores)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c2234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_init()\n",
    "tokenizer = return_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0289c97",
   "metadata": {},
   "source": [
    "- 3181878 개의 네이버 종목토론방, 유튜브 댓글을 학습시키고, 학습된 tokenizer를 이용하여 전처리 댓글을 토큰화 시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c9b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = clean_sents_df('삼성전자')\n",
    "target_df['토큰화 댓글'] = [tokenizer(str(i)) for i in target_df['정제된 댓글']]\n",
    "target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765422c1",
   "metadata": {},
   "source": [
    "### 2.3 댓글 레이블링\n",
    "- fear_words_set 과 greed_words_set을 설정하고 토크나이징댓글의 요소가 fear 단어집에 있으면 -1씩 greed 단어집에 있으면 +1씩 부여했습니다.\n",
    "- 양수인경우 greed, 음수인경우 fear로 labeling 했습니다. 0 인경우 일단 데이터프레임에 기록되고, 최종적으로 train_data 선정시에는 제외됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c81e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(target_df):\n",
    "    \n",
    "    f = open(\"./neg_pol_word.txt\", 'r',encoding='utf8')\n",
    "    words = f.readlines()\n",
    "    f.close()\n",
    "    fear_words_set = {word.strip('\\n') for word in words}\n",
    "\n",
    "    f = open(\"./pos_pol_word.txt\", 'r',encoding='utf8')\n",
    "    words = f.readlines()\n",
    "    f.close()\n",
    "    greed_words_set = {word.strip('\\n') for word in words}\n",
    "    \n",
    "    label_score = []\n",
    "    for token_list in target_df['토큰화 댓글']:\n",
    "        sent_score = 0\n",
    "        for token in token_list:\n",
    "            if token in fear_words_set:\n",
    "                sent_score -= 1\n",
    "            elif token in greed_words_set:\n",
    "                sent_score += 1\n",
    "\n",
    "        if sent_score < 0:\n",
    "            label_score.append(-1)\n",
    "        elif sent_score > 0:\n",
    "            label_score.append(1)\n",
    "        else:\n",
    "            label_score.append(0)\n",
    "            \n",
    "    target_df['label'] = label_score\n",
    "    \n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c142d956",
   "metadata": {},
   "source": [
    "### 2.4 학습데이터 생성\n",
    "\n",
    "- 학습데이터는 종목토론실 댓글에서 3만개, 유튜브 댓글에서 1만개 랜덤추출 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831a4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting_train_data():\n",
    "    company = list(pd.read_excel('./KODEX_KTOP_30_20220715.xls',header=2)['종목명'][1:])\n",
    "    dominance = list(pd.read_excel('./KODEX_KTOP_30_20220715.xls',header=2)['비중(%)'][1:])\n",
    "\n",
    "    train_data = pd.DataFrame(columns=['날짜','댓글','조회수','좋아요','싫어요','정제된 댓글','토큰화 댓글','label'])\n",
    "    for idx in range(30):\n",
    "        target_df = clean_sents_df(company[idx])\n",
    "        target_df['토큰화 댓글'] = [tokenizer(str(i)) for i in target_df['정제된 댓글']]\n",
    "        \n",
    "        label_df = labeling(target_df)\n",
    "        \n",
    "        label_df = label_df[label_df['label'] != 0] # except label:0 \n",
    "        label_df = label_df.sample(int(30000*dominance[idx])+1,replace=True) # replace option : 샘플수가 부족할경우 중복이 생김 ** 추후 수정\n",
    "        train_data = train_data.append(label_df)\n",
    "    \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c884cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = setting_train_data()\n",
    "train_data.reset_index(inplace=True)\n",
    "train_data.drop('index',axis=1,inplace=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e6bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삼프로\n",
    "target_df = clean_sents_df('sampro')\n",
    "target_df['토큰화 댓글'] = [tokenizer(str(i)) for i in target_df['정제된 댓글']]\n",
    "label_df = labeling(target_df)\n",
    "\n",
    "label_df = label_df[label_df['label'] != 0] # except label:0 \n",
    "label_df = label_df.sample(10000,replace=True) # replace option : 샘플수가 부족할경우 중복이 생김 ** 추후 수정\n",
    "train_data = train_data.append(label_df)\n",
    "\n",
    "train_data = train_data.loc[:,['정제된 댓글','label']].reset_index().drop('index',axis=1)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d72d56",
   "metadata": {},
   "source": [
    "## chapter 3. Bert 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b6639d",
   "metadata": {},
   "source": [
    "### 3.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622b870",
   "metadata": {},
   "source": [
    "## chapter 4. 시각화 및 서비스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3efc026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d7a93d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2bc543695463befc13840ec3d47f38ad407b1992c7ad047a9a3023a6d142e755"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
