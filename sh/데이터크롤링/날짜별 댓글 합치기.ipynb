{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 날짜별 댓글 합치기\n",
    "+ youtube 폴더의 sampro 파일은 유튜브 댓글 로우데이터\n",
    "+ 그 외 종토방 댓글은 실시간 크롤링으로 받아옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "\n",
    "import datetime\n",
    "import scrapetube\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "import soynlp\n",
    "from soynlp.noun import LRNounExtractor_v2\n",
    "from soynlp import DoublespaceLineCorpus\n",
    "from soynlp.word import WordExtractor\n",
    "from soynlp.tokenizer import LTokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# root path 설정\n",
    "root_path = \"C:/sh/study/krx데이콘/krx_2022/sh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종목코드 가져오는 코드\n",
    "def get_code(symbol):\n",
    "    krx = pd.read_csv(root_path + '/data/code/krx_code.csv',encoding='utf-8')\n",
    "    krx = krx.set_index('한글 종목약명')\n",
    "    try:\n",
    "        code = krx.at[symbol,'단축코드']\n",
    "        return code\n",
    "    except:\n",
    "        print('종목명을 다시 확인해주세요.')\n",
    "        return 0\n",
    "\n",
    "# 종토방 댓글 가져오는 코드\n",
    "def get_comment_csv(symbol,page,year,month,day):   \n",
    "    code = get_code(symbol)\n",
    "    date_list = [] # 날짜\n",
    "    comment_list = [] # 댓글\n",
    "    view_list = [] # 조회수\n",
    "    good_list = [] # 좋아요\n",
    "    bad_list = [] # 싫어요\n",
    "    flag = 0\n",
    "    for i in range(1,page+1):\n",
    "        url = f'https://finance.naver.com/item/board.naver?code={code}&page={i}'\n",
    "        headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 Edg/100.0.1185.50'}\n",
    "        res = requests.get(url, headers = headers)\n",
    "        bs = BeautifulSoup(res.text, 'html.parser')\n",
    "        for j in range(20):\n",
    "            try:\n",
    "                root = bs.find('div',{'class':'section inner_sub'}).find_all('tr',{'onmouseover':'mouseOver(this)'})[j].text.split('\\n')\n",
    "                \n",
    "                date_list.append(root[1].replace('.','-'))\n",
    "                \n",
    "                if len(root) == 14: # 답글\n",
    "                    comment_list.append('답글:'+root[4])\n",
    "                    view_list.append(root[10])\n",
    "                    good_list.append(root[11])\n",
    "                    bad_list.append(root[12])          \n",
    "                elif len(root) == 13: # 기본\n",
    "                    comment_list.append(root[3])\n",
    "                    view_list.append(root[9])\n",
    "                    good_list.append(root[10])\n",
    "                    bad_list.append(root[11])\n",
    "                else: # 에러\n",
    "                    comment_list.append('error')\n",
    "                    view_list.append(0)\n",
    "                    good_list.append(0)\n",
    "                    bad_list.append(0)   \n",
    "            except:\n",
    "                break\n",
    "            tp = [int(j) for j in root[1].split()[0].split('.')]\n",
    "            if dt.datetime(tp[0],tp[1],tp[2]) < dt.datetime(year,month,day):\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 1:\n",
    "            break\n",
    "        print(f'\\r{i}페이지 크롤링 완료.',end='')\n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    df['날짜'] = date_list\n",
    "    df['댓글'] = comment_list\n",
    "    df['조회수'] = view_list\n",
    "    df['좋아요'] = good_list\n",
    "    df['싫어요'] = bad_list\n",
    "    return df\n",
    "\n",
    "# 종목이름 가져오는 코드\n",
    "def get_company_name():\n",
    "    df = pd.read_excel(root_path + '/data/code/KODEX_KTOP_30_20220629.xlsx',header=2).drop(0,axis=0)\n",
    "    return df.종목명.tolist()\n",
    "\n",
    "# 해당 년,월,일까지 종토방 댓글 가져오는 코드\n",
    "# 종목이름 순서대로 각 데이터프레임을 리스트에 저장하여 반환\n",
    "def get_date_comment(year,month,day):\n",
    "    c_list = get_company_name()\n",
    "    data_list = []\n",
    "    for company in c_list:\n",
    "        print(company,\"크롤링\")\n",
    "        df = get_comment_csv(company,10000,year,month,day)\n",
    "        data_list.append(df)\n",
    "        print()\n",
    "    return data_list\n",
    "\n",
    "# 특수문자 제거\n",
    "def clean_sents_df(target):\n",
    "    df = target\n",
    "    df['정제된 댓글'] = df['댓글'].str.replace('\\\\[삭제된 게시물의 답글\\\\]',' ')\n",
    "    df['정제된 댓글'] = df['정제된 댓글'].str.replace('답글:',' ')\n",
    "    df['정제된 댓글'] = df['정제된 댓글'].str.replace('[^가-힣]',' ').str.replace(' +',' ').str.strip()\n",
    "    df = df[df['정제된 댓글'] != '']\n",
    "    df = df.reset_index(drop=True)\n",
    "    return  df\n",
    "\n",
    "# 댓글 토큰화를 위한 말뭉치 준비\n",
    "def return_tokenizer():\n",
    "    corpus = DoublespaceLineCorpus(root_path + \"/data/code/corpus_target.txt\",iter_sent=True)\n",
    "    noun_extractor = LRNounExtractor_v2(verbose=True)\n",
    "    nouns = noun_extractor.train_extract(corpus)\n",
    "    scores = {word:score.score for word, score in nouns.items()}\n",
    "    tokenizer = LTokenizer(scores=scores)\n",
    "    return tokenizer\n",
    "\n",
    "# 오늘의 댓글 데이터를 저장 후 반환\n",
    "def get_data_list():\n",
    "    # 2022-06-01 데이터부터 가져옴\n",
    "    data_list = get_date_comment(2022,6,1)\n",
    "    date = str(datetime.datetime.today())[:10]\n",
    "    df = pd.read_csv(root_path + f\"/data/youtube/sampro.csv\")\n",
    "    data_list.append(df)\n",
    "    return data_list\n",
    "\n",
    "# 각 데이터를 전처리 후 리스트에 저장\n",
    "def comment_prep(data_list):\n",
    "    tokenizer = return_tokenizer()\n",
    "\n",
    "    pp_list = []\n",
    "    for company_data in data_list:\n",
    "        target_df = clean_sents_df(company_data)\n",
    "        target_df['토큰화 댓글'] = [tokenizer(str(i)) for i in target_df['정제된 댓글']]\n",
    "        pp_list.append(target_df)\n",
    "    \n",
    "    for df in pp_list:\n",
    "        date_list = []\n",
    "        for i in range(len(df[\"날짜\"])):\n",
    "            date_list.append(df[\"날짜\"][i][:10])\n",
    "        df[\"날짜\"] = date_list\n",
    "    \n",
    "    return pp_list\n",
    "\n",
    "# 댓글 크롤링, 전처리, 파일로 저장\n",
    "def date_crawler():\n",
    "    data_list = get_data_list()\n",
    "    pp_list = comment_prep(data_list)\n",
    "    df_day = pp_list[0]\n",
    "    for i in range(1,len(pp_list)):\n",
    "        df_day = pd.concat([df_day, pp_list[i]])\n",
    "    today = str(datetime.datetime.today())[:10]\n",
    "    df_day = df_day[[\"날짜\",\"정제된 댓글\"]]\n",
    "    df = df_day[df_day[\"날짜\"] == today]\n",
    "    df.dropna(inplace=True)\n",
    "    df.to_csv(root_path + f\"/data/alldf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 날짜로 체크\n",
    "target_date = ['2022-06-01', '2022-06-02', '2022-06-03', '2022-06-04', '2022-06-05',\n",
    "               '2022-06-06', '2022-06-07', '2022-06-08', '2022-06-09', '2022-06-10',\n",
    "               '2022-06-11', '2022-06-12', '2022-06-13', '2022-06-14', '2022-06-15',\n",
    "               '2022-06-16', '2022-06-17', '2022-06-18', '2022-06-19', '2022-06-20',\n",
    "               '2022-06-21', '2022-06-22', '2022-06-23', '2022-06-24', '2022-06-25',\n",
    "               '2022-06-26', '2022-06-27', '2022-06-28', '2022-06-29', '2022-06-30',\n",
    "               '2022-07-01', '2022-07-02', '2022-07-03', '2022-07-04', '2022-07-05',\n",
    "               '2022-07-06', '2022-07-07', '2022-07-08', '2022-07-09', '2022-07-10',\n",
    "               '2022-07-11', '2022-07-12', '2022-07-13', '2022-07-14', '2022-07-15',\n",
    "               '2022-07-16', '2022-07-17', '2022-07-18', '2022-07-19', '2022-07-20',\n",
    "               '2022-07-21', '2022-07-22', '2022-07-23', '2022-07-24', '2022-07-25',\n",
    "               '2022-07-26', '2022-07-27', '2022-07-28', '2022-07-29', '2022-07-30',\"2022-07-31\",\n",
    "               '2022-08-01', '2022-08-02', '2022-08-03', '2022-08-04', '2022-08-05',\n",
    "               '2022-08-06', '2022-08-07', '2022-08-08', '2022-08-09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자 크롤링\n",
      "2660페이지 크롤링 완료."
     ]
    }
   ],
   "source": [
    "date_crawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(root_path + f\"/data/alldf.csv\")\n",
    "\n",
    "for date in target_date:\n",
    "    df2 = df[df[\"날짜\"]==date]\n",
    "    df2.to_csv(root_path + f\"/data/date/{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bc543695463befc13840ec3d47f38ad407b1992c7ad047a9a3023a6d142e755"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
